
@inproceedings{Layman2022,
	abstract = {Abstract—Research suggests that neck strength measurements may predict risk of mild Traumatic Brain Injuries (mTBIs), such as concussions. However, existing neck strength assessment tools are often unreliable or immobile. This article describes a prototype of a portable neck strength measurement system. The prototype consists of off-the-shelf hardware components paired with a cross-platform mobile application that guides the user through the assessment protocol, records neck strength readings over Bluetooth Low Energy (BLE), and saves subject records to a cloud database. A heuristic evaluation identifies improvements to implement in the mobile application. Lessons learned on creating BLE-enabled hardware/software pairings are presented. Future work includes integrating predictive algorithms for mTBI risk, miniaturizing the hardware design, and a field evaluation.},
	author = {Lucas Layman and Alexander T McDaniel and Lindsey H Schroeder},
	city = {Mobile, AL, USA},
	doi = {10.1109/SoutheastCon48659.2022.9764138},
	isbn = {9781665406529},
	journal = {Proceedings of IEEE SoutheastCon 2022},
	pages = {348-354},
	title = {A Portable, Bluetooth-Enabled, Isometric Neck Assessment System},
	year = {2022},
}
@inproceedings{Layman2022a,
	abstract = {The Coastal Eco Explorer is an Apple and Android mobile application that delivers educational information for 64 ecological sites in Carolina Beach State Park. The app is an interdisciplinary collaboration between university faculty and state park rangers to educate park visitors. The Coastal Eco Explorer was launched in March 2021 and has several hundred users. This article describes the genesis of the Coastal Eco Explorer project, its technical architecture, and its current functionality. The app is the first official app published by the university. The app’s development yielded several lessons learned of interest to educators interested in developing published enduser software.},
	author = {Lucas Layman and Amy R Taylor and Dennis S Kubasko Jr. and Kinsley A Sigmund and Avery C Owen},
	city = {Mobile, AL, USA},
	doi = {10.1109/SoutheastCon48659.2022.9763935},
	isbn = {9781665406529},
	journal = {Proceedings of IEEE SoutheastCon 2022},
	pages = {391-396},
	title = {Coastal Eco Explorer: A Mobile Application for Ecology Education},
	year = {2022},
}

@article{Dodson2022a,
	author = {Crystal Dodson and Lucas Layman},
	doi = {10.21037/atm-2022-68},
	issn = {23055839},
	issue = {23},
	journal = {Annals of Translational Medicine},
	month = {12},
	pages = {Article 1261},
	title = {Refinement of a pharmacogenomics app for dosing guidelines for oncology: findings from the usability evaluation},
	volume = {10},
	url = {https://atm.amegroups.com/article/view/104765/html},
	year = {2022},
}

@article{Dodson2022,
	author = {Crystal Heath Dodson and Lucas Layman},
	doi = {10.1097/CIN.0000000000000960},
	issue = {-},
	journal = {Computers, Informatics, Nursing},
	title = {Interdisciplinary Collaboration among Nursing and Computer Science to Refine a Pharmacogenetics Clinical Decision Support Tool via Mobile Application},
	volume = {-},
	year = {2022},
}

@inproceedings{Roden2020,
address = {Tampa, FL, USA},
author = {Roden, William and Layman, Lucas},
booktitle = {Proceedings of the 2020 ACM Southeast Conference (ACMSE 2020)},
doi = {10.1145/3374135.3385301},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Roden, Layman - 2020 - Cry Wolf Toward an Experimentation Platform and Dataset for Human Factors in Cyber Security Analysis(2).pdf:pdf},
pages = {264--267},
publisher = {ACM},
title = {{Cry Wolf : Toward an Experimentation Platform and Dataset for Human Factors in Cyber Security Analysis}},
url = {https://arxiv.org/abs/2002.10530},
year = {2020}
}
@misc{Roden2019a,
author = {Roden, William and Layman, Lucas},
booktitle = {GitHub},
title = {{The Cry Wolf IDS Simulator - An environment for conducting controlled experiments of cyber security analysis tasks}},
url = {https://uncw-hfcs.github.io/ids-simulator/},
urldate = {2020-09-16},
year = {2019}
}
@misc{Roden,
author = {Roden, Williams and Layman, Lucas},
booktitle = {GitHub},
title = {{The Cry Wolf Dataset - A repository of simulated IDS alerts for experimentation}},
url = {https://uncw-hfcs.github.io/ids-simulator-analysis/},
urldate = {2020-09-16},
year = {2019}
}
@inproceedings{Layman2014b,
abstract = {While automated methods are the first line of defense for detecting attacks on webservers, a human agent is required to understand the attacker's intent and the attack process. The goal of this research is to understand the value of various log fields and the cognitive processes by which log information is grouped, searched, and correlated. Such knowledge will enable the development of human-focused log file investigation technologies. We performed controlled experiments with 65 subjects (IT professionals and novices) who investigated excerpts from six Webserver log files. Quantitative and qualitative data were gathered to: 1) analyze subject accuracy in identifying malicious activity; 2) identify the most useful pieces of log file information; and 3) understand the techniques and strategies used by subjects to process the information. Statistically significant effects were observed in the accuracy of identifying attacks and time taken depending on the type of attack. Systematic differences were also observed in the log fields used by high-performing and low-performing groups. The findings include: 1) new insights into how specific log data fields are used to effectively assess potentially malicious activity; 2) obfuscating factors in log data from a human cognitive perspective; and 3) practical implications for tools to support log file investigations. Copyright 2014 ACM.},
address = {Raleigh, NC},
author = {Layman, Lucas and Diffo, Sylvain David and Zazworka, Nico},
booktitle = {Proc. of the 2014 Symposium and Bootcamp on the Science of Security (HotSoS '14)},
doi = {10.1145/2600176.2600185},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Layman, Diffo, Zazworka - 2014 - Human Factors in Webserver Log File Analysis A Controlled Experiment on Investigating Malicious Acti(2).pdf:pdf},
isbn = {9781450329071},
keywords = {Human factors,Log files,Science of security,Security,mypubs,security},
mendeley-tags = {mypubs,security},
pages = {9:1--9:11},
title = {{Human Factors in Webserver Log File Analysis: A Controlled Experiment on Investigating Malicious Activity}},
year = {2014}
}
@misc{Layman2020a,
address = {Wilmington, NC},
author = {Layman, Lucas and Sigmund, Kinsley and Taylor, Amy R. and Kubasko, Dennis S. and Owen, Avery C.},
title = {{Coastal Eco Explorer}},
url = {https://github.com/uncw-hfcs/cbsp-ecosystem-explorer},
year = {2020}
}
@inproceedings{Song2020,
address = {Tampa, FL, USA},
author = {Song, Yang and Xiao, Yunkai and Stephens, Jonathan and Ruesch, Emma and Roginski, Sean and Layman, Lucas},
booktitle = {Proceedings of the 2020 ACM Southeast Conference (ACMSE 2020)},
doi = {10.1145/3374135.3385277},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - 2020 - Suitability of SCS1 as a Pre-CS2 Assessment Instrument A Comparison with Short Deliberate-practice Questions.pdf:pdf},
pages = {2},
title = {{Suitability of SCS1 as a Pre-CS2 Assessment Instrument : A Comparison with Short Deliberate-practice Questions}},
year = {2020}
}
@inproceedings{Layman2020,
abstract = {Factors driving success and failure in CS1 are the subject of much study but less so for CS2. This paper investigates the transition from CS1 to CS2 in search of leading indicators of success in CS2. Both CS1 and CS2 at the University of North Carolina Wilmington (UNCW) are taught in Python with annual enrollments of 300 and 150 respectively. In this paper, we report on the following research questions: (1) Are CS1 grades indicators of CS2 grades? (2) Does a quantitative relationship exist between CS2 course grade and a modified version of the SCS1 concept inventory? (3) What are the most challenging aspects of CS2, and how well does CS1 prepare students for CS2 from the student's perspective? We provide a quantitative analysis of 2300 CS1 and CS2 course grades from 2013–2019. In Spring 2019, we administered a modified version of the SCS1 concept inventory to 44 students in the first week of CS2. Further, 69 students completed an exit questionnaire at the conclusion of CS2 to gain qualitative student feedback on their challenges in CS2 and on how well CS1 prepared them for CS2. We find that 56{\%} of students' grades were lower in CS2 than CS1, 18{\%} improved their grades, and 26{\%} earned the same grade. Of the changes, 62{\%} were within one grade point. We find a statistically significant correlation between the modified SCS1 score and CS2 grade points. Students identify linked lists and class/object concepts among the most challenging. Student feedback on CS2 challenges and the adequacy of their CS1 preparations identify possible avenues for improving the CS1-CS2 transition.},
address = {Tampa, FL, USA},
author = {Layman, Lucas and Song, Yang and Guinn, Curry},
booktitle = {Proceedings of the 2020 ACM Southeast Conference (ACMSE 2020)},
doi = {10.1145/3374135.3385277},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Layman, Song, Guinn - 2020 - Toward Predicting Success and Failure in CS2 A Mixed-Method Analysis.pdf:pdf},
pages = {8},
publisher = {ACM},
title = {{Toward Predicting Success and Failure in CS2 : A Mixed-Method Analysis}},
url = {https://arxiv.org/abs/2002.11813},
year = {2020}
}
@article{Sabottke2019,
abstract = {Cyber attackers constantly craft new attacks previously unknown to the security community. There are two approaches for detecting such attacks: (1) employing human analysts who can observe the data and identify anomalies that correspond to malicious intent; and (2) utilizing unsupervised automated techniques, such as clustering, that do not rely on ground truth. We conduct a security analysis of the two approaches, utilizing attacks against a real-world website. Through two experiments—a user study with 65 security analysts and an experimental analysis of attack discovery using DBSCAN clustering—we compare the strategies and features employed by human analysts and clustering system for detecting attacks. Building on these observations, we propose threat models for the human analysis process and for the unsupervised techniques when operating in adversarial settings. Based on our analysis, we propose and evaluate two attacks against the DBSCAN clustering algorithm and a defense. Finally, we discuss the implications of our insights for hybrid systems that utilize the strengths of automation and of human analysis to complement their respective weaknesses.},
author = {Sabottke, Carl and Chen, Daniel and Layman, Lucas and Dumitraş, Tudor},
doi = {10.1016/J.COSE.2018.07.022},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sabottke et al. - 2019 - How to trick the Borg threat models against manual and automated techniques for detecting network attacks.pdf:pdf},
issn = {0167-4048},
journal = {Computers {\&} Security},
month = {mar},
pages = {25--40},
publisher = {Elsevier Advanced Technology},
title = {{How to trick the Borg: threat models against manual and automated techniques for detecting network attacks}},
url = {https://www.sciencedirect.com/science/article/pii/S0167404818311283},
volume = {81},
year = {2019}
}
@incollection{Shull2013,
abstract = {{\textcopyright} 2013 Springer-Verlag Berlin Heidelberg. All rights are reserved. In this chapter, we discuss recent progress and opportunities in empirical software engineering by focusing on a particular technology, Technical Debt (TD), which ties together many recent developments in the field. Recent advances in TD research are providing empiricists the chance to make more sophisticated recommendations that have observable impact on practice. TD uses a financial metaphor and provides a framework for articulating the notion of tradeoffs between the short-term benefits and the long-term costs of software development decisions. TD is seeing an explosion of interest in the practitioner community, and research in this area is quickly having an impact on practice. We argue that this is due to several strands of empirical research reaching a level of maturity that provides useful benefits to practitioners, who in turn provide excellent data to researchers. They key is providing observable benefit to practitioners, such as the ability to tie technical debt measures to business goals, and the ability to articulate more sophisticated value-based propositions regarding how to prioritize rework. TD is an interesting case study in how the maturing field of empirical software engineering research is paying dividends. It is only a little hyperbolic to call this a watershed moment for empirical study, where many areas of progress are coming to a head at the same time.},
author = {Shull, Forrest and Falessi, Davide and Seaman, Carolyn and Diep, Madeline and Layman, Lucas},
booktitle = {Perspectives on the Future of Software Engineering: Essays in Honor of Dieter Rombach},
doi = {10.1007/978-3-642-37395-4_12},
editor = {M{\"{u}}nch, J{\"{u}}rgen and Schmid, Klaus},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shull et al. - 2013 - Technical Debt Showing the Way for Better Transfer of Empirical Results.pdf:pdf},
isbn = {9783642373954},
keywords = {mypubs},
mendeley-tags = {mypubs},
pages = {179--190},
publisher = {Elsevier},
title = {{Technical Debt: Showing the Way for Better Transfer of Empirical Results}},
volume = {9783642373},
year = {2013}
}
@article{Layman2008,
abstract = {The software industry uses a mixture of plan-driven and agile techniques, and educators must prepare students for industry needs while creating an effective educational environment that appeals to a diverse student population. We describe the undergraduate course in software engineering at North Carolina State University, which teaches both agile and plan-driven practices while emphasizing collaborative and active learning. We present demographics, personality types, and learning styles from 400 students, and provide statistical analyses and student testimonials on the impact of our course. Students have reacted favorably to the course and are better prepared to meet the diverse needs of industry. {\textcopyright} 2008 TEMPUS Publications.},
author = {Layman, Lucas and Williams, Laurie and Slaten, Kelli and Berenson, Sarah and Vouk, Mladen},
issn = {0949149X},
journal = {International Journal of Engineering Education},
keywords = {Agile methods,Learning styles,Personality types,Software engineering education,mypubs},
mendeley-tags = {mypubs},
number = {4},
pages = {659--670},
title = {{Addressing Diverse Needs through a Balance of Agile and Plan-driven Software Development Methodologies in the Core Software Engineering Course}},
volume = {24},
year = {2008}
}
@inproceedings{Williams2006a,
abstract = {Pair programming has been shown to be beneficial for both students and teaching staff in university courses. A two-phased study of 1350 students was conducted at North Carolina State University from 2002-2005 to determine if teaching staff can proactively form compatible pairs based upon any of the following factors: personality type, learning style, skill level, programming self esteem, work ethic, or time management preference. We examined compatibility among freshmen, advanced undergraduate and graduate student pair programmers. We have found that overall 93{\%} of students are compatible with their partners. Students notably preferred to pair with a partner that he or she perceived to be of similar or higher skill level to them, which can be predicted by grouping students with similar grade point average. Additionally, pairs comprised of a sensor and an intuitor learning style seem to be compatible, and pairs with differing work ethic are generally not compatible},
address = {Minneapolis, MN},
author = {Williams, Laurie and Layman, Lucas and Osborne, Jason and Katira, Neha},
booktitle = {AGILE 2006 (AGILE'06)},
doi = {10.1109/AGILE.2006.25},
isbn = {0-7695-2562-8},
keywords = {Collaboration,Collaborative work,Computer science,Education,Ethics,Information technology,North Carolina State University,Peer to peer computing,Programming profession,Statistics,Testing,advanced undergraduate student pair programmers,computer science education,continuing education,educational courses,ethical aspects,freshmen student pair programmers,graduate student pair programmers,human factors,intuitor learning style,mypubs,personality type,programming,programming self esteem,skill level,teaching,teaching staff,time management preference,university courses,work ethic},
mendeley-tags = {mypubs},
pages = {411--420},
publisher = {IEEE},
shorttitle = {Agile Conference, 2006},
title = {{Examining the Compatibility of Student Pair Programmers}},
year = {2006}
}
@inproceedings{Layman2007b,
abstract = {The longer a fault remains in the code from the time it was injected, the more time it will take to fix the fault. Increasingly, automated fault detection (AFD) tools are providing developers with prompt feedback on recently-introduced faults to reduce fault fix time. If however, the frequency and content of this feedback does not match the developer's goals and/or workflow, the developer may ignore the information. We conducted a controlled study with 18 developers to explore what factors are used by developers to decide whether or not to address a fault when notified of the error. The findings of our study lead to several conjectures about the design of AFD tools to effectively notify developers of faults in the coding phase. The AFD tools should present fault information that is relevant to the primary programming task with accurate and precise descriptions. The fault severity and the specific timing of fault notification should be customizable. Finally, the AFD tool must be accurate and reliable to build trust with the developer.},
address = {Madrid, Spain},
author = {Layman, Lucas and Williams, Laurie and {St. Amant}, Robert},
booktitle = {First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007)},
doi = {10.1109/ESEM.2007.11},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Layman, Williams, St. Amant - 2007 - Toward Reducing Fault Fix Time Understanding Developer Behavior for the Design of Automated Fault D.pdf:pdf},
isbn = {978-0-7695-2886-1},
issn = {1938-6451},
keywords = {AFD tools,Automatic control,Computer science,Error correction,Fault detection,Feedback,Frequency,Software engineering,Software measurement,Time measurement,Timing,automated fault detection tools,developer behavior,fault diagnosis,fault fix time,fault information,fault notification,fault severity,mypubs,software tools},
mendeley-tags = {mypubs},
month = {sep},
pages = {176--185},
publisher = {IEEE},
shorttitle = {Empirical Software Engineering and Measurement, 20},
title = {{Toward Reducing Fault Fix Time: Understanding Developer Behavior for the Design of Automated Fault Detection Tools}},
year = {2007}
}
@inproceedings{Layman2005b,
abstract = {This paper presents the results of an initial quantitative investigation to assess a variety of factors that potentially affect the collaborative software development experience. This research was conducted with 119 students in two undergraduate software engineering classes at North Carolina State University. A survey was administered where students could reflect on their collaborative experiences. We analyzed these factors for interrelationships as well as for correlations with performance in the course, grade point average, and SAT scores. Our findings support the components of the proposed Social Interaction Model of Pair Programming. The substantiation of the Social Interaction Model of Pair Programming values suggests that they should be considered in course planning. We also find that work ethic and self-perceived programming ability positively correlate with GPA},
address = {Indianapolis, Indiana},
author = {Layman, Lucas and Williams, Laurie and Osborne, Jason and Berenson, Sarah and Slaten, Kelli and Vouk, Mladen and {L. Williams}, L and Osborne, Jason and Berenson, Sarah and Slaten, Kelli and Vouk, Mladen},
booktitle = {Proceedings Frontiers in Education 35th Annual Conference},
doi = {10.1109/FIE.2005.1611964},
isbn = {0-7803-9077-6},
issn = {0190-5848},
keywords = {Collaborative development,Collaborative software,Collaborative work,Computer science,Computer science education,Education research,Educational programs,Educational technology,Engineering profession,LS,MBTI,Mathematics,North Carolina State University,Programming profession,Software engineering,collaborative software development,educational courses,educational institutions,ethical aspects,learning,mypubs,pair programming,quantitative investigation,self-perceived programming ability,social interaction model,software engineering classes,software engineering course,survey,work ethic},
mendeley-tags = {mypubs},
pages = {T4C 9--14},
publisher = {IEEE},
shorttitle = {Frontiers in Education, 2005. FIE '05. Proceedings},
title = {{How and Why Collaborative Software Development Impacts the Software Engineering Course}},
year = {2005}
}
@article{Krishna2017,
abstract = {{\textcopyright} 2017 Elsevier B.V. Context: Developers use bad code smells to guide code reorganization. Yet developers, textbooks, tools, and researchers disagree on which bad smells are important. How can we offer reliable advice to developers about which bad smells to fix? Objective: To evaluate the likelihood that a code reorganization to address bad code smells will yield improvement in the defect-proneness of the code. Method: We introduce XTREE, a framework that analyzes a historical log of defects seen previously in the code and generates a set of useful code changes. Any bad smell that requires changes outside of that set can be deprioritized (since there is no historical evidence that the bad smell causes any problems). Evaluation: We evaluate XTREE's recommendations for bad smell improvement against recommendations from previous work (Shatnawi, Alves, and Borges) using multiple data sets of code metrics and defect counts. Results: Code modules that are changed in response to XTREE's recommendations contain significantly fewer defects than recommendations from previous studies. Further, XTREE endorses changes to very few code metrics, so XTREE requires programmers to do less work. Further, XTREE's recommendations are more responsive to the particulars of different data sets. Finally XTREE's recommendations may be generalized to identify the most crucial factors affecting multiple datasets (see the last figure in paper). Conclusion: Before undertaking a code reorganization based on a bad smell report, use a framework like XTREE to check and ignore any such operations that are useless; i.e. ones which lack evidence in the historical record that it is useful to make that change. Note that this use case applies to both manual code reorganizations proposed by developers as well as those conducted by automatic methods.},
archivePrefix = {arXiv},
arxivId = {1609.03614},
author = {Krishna, Rahul and Menzies, Tim and Layman, Lucas},
doi = {10.1016/j.infsof.2017.03.012},
eprint = {1609.03614},
file = {:C$\backslash$:/Users/laymanl/Desktop/layman pubs/Krishna2017.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Bad smells,Decision trees,Performance prediction},
pages = {53--66},
title = {{Less is More: Minimizing Code Reorganization using XTREE}},
url = {https://arxiv.org/pdf/1609.03614.pdf},
volume = {88},
year = {2017}
}
@misc{Williams2004a,
address = {North Carolina State University, Department of Computer Science TR-2003-20},
author = {Williams, L and Krebs, W and Layman, L and Krebs, W and Layman, L},
isbn = {TR-2004-18},
keywords = {mypubs},
mendeley-tags = {mypubs},
publisher = {North Carolina State University Department of Computer Science},
title = {{Extreme Programming Evaluation Framework for Object-Oriented Languages -- Version 1.1}},
year = {2004}
}
@inproceedings{Layman2013,
abstract = {We know surprisingly little about how professional developers define debugging and the challenges they face in industrial environments. To begin exploring professional debugging challenges and needs, we conducted and analyzed interviews with 15 professional software engineers at Microsoft. The goals of this study are: 1) to understand how professional developers currently use information and tools to debug; 2) to identify new challenges in debugging in contemporary software development domains (web services, multithreaded/multicore programming); and 3) to identify the improvements in debugging support desired by these professionals that are needed from research. The interviews were coded to identify the most common information resources, techniques, challenges, and needs for debugging as articulated by the developers. The study reveals several debugging challenges faced by professionals, including: 1) the interaction of hypothesis instrumentationand software environment as a source of debugging difficulty; 2) the impact of log file information on accurate debugging of web services; and 3) the mismatch between the sequential human thought process and the non-sequential execution of multithreaded environments as source of difficulty. The interviewees also describe desired improvements to tools to support debugging, many of which have been discussed in research but not transitioned to practice.},
address = {Baltimore, Maryland, USA},
author = {Layman, Lucas and Diep, Madeline and Nagappan, Meiyappan and Singer, Janice and DeLine, Robert and Venolia, Gina},
booktitle = {2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2013.43},
isbn = {978-0-7695-5056-5},
issn = {1938-6451},
keywords = {debugging,interview,microsoft,mypubs,professionals,program comprehension,qualitative analysis,software engineering},
mendeley-tags = {debugging,interview,microsoft,mypubs},
month = {oct},
pages = {383--392},
publisher = {IEEE},
shorttitle = {Empirical Software Engineering and Measurement, 20},
title = {{Debugging Revisited: Toward Understanding the Debugging Needs of Contemporary Software Developers}},
year = {2013}
}
@article{Menzies2013,
abstract = {Existing research is unclear on how to generate lessons learned for defect prediction and effort estimation. Should we seek lessons that are global to multiple projects or just local to particular projects? This paper aims to comparatively evaluate local versus global lessons learned for effort estimation and defect prediction. We applied automated clustering tools to effort and defect datasets from the PROMISE repository. Rule learners generated lessons learned from all the data, from local projects, or just from each cluster. The results indicate that the lessons learned after combining small parts of different data sources (i.e., the clusters) were superior to either generalizations formed over all the data or local lessons formed from particular projects. We conclude that when researchers attempt to draw lessons from some historical data source, they should 1) ignore any existing local divisions into multiple sources, 2) cluster across all available data, then 3) restrict the learning of lessons to the clusters from other sources that are nearest to the test data.},
author = {Menzies, Tim and Butcher, Andrew and Cok, David and Marcus, Andrian and Layman, Lucas and Shull, Forrest and Turhan, Burak and Zimmermann, Thomas},
doi = {10.1109/TSE.2012.83},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Context,Data mining,Data models,Estimation,Java,Measurement,PROMISE repository,Software,Telecommunications,agile,automated clustering tools,automatic test pattern generation,clustering,data mining,data source,defect dataset,defect prediction,effort estimation,global lessons,learned lesson generated rule,local lessons,mypubs,nsf,pattern clustering},
language = {English},
mendeley-tags = {agile,clustering,data mining,defect prediction,effort estimation,mypubs,nsf},
month = {jun},
number = {6},
pages = {822--834},
publisher = {IEEE},
title = {{Local versus Global Lessons for Defect Prediction and Effort Estimation}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6363444},
volume = {39},
year = {2013}
}
@inproceedings{Williams2007b,
abstract = {Despite many professed benefits of collaboration, some computer science educators feel students need to master work individually, particularly in the courses early in the curriculum that feed into software engineering courses. In the natural sciences, however, students almost always work with one or more partners in the laboratory. What can computer science educators learn about collaborative lab settings from our natural science counterparts? We conducted a survey of science and computer science educators to compare views and use of collaboration in their classes. The positive and negative aspects of collaboration, as reported by the natural science educators, are strikingly similar to those of computer science educators. These results suggest that computer science educators should be more open to the use of collaborative labs, as is done in the natural sciences, for the overall benefit to students.},
address = {Dublin, Ireland},
author = {Williams, Laurie and Layman, Lucas},
booktitle = {20th Conference on Software Engineering Education and Training (CSEET'07)},
doi = {10.1109/CSEET.2007.31},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Williams, Layman - 2007 - Lab Partners If They're Good Enough for the Sciences, Why Aren't They Good Enough for Us.pdf:pdf},
isbn = {0-7695-2893-7},
issn = {1093-0175},
keywords = {Biology,Chemistry,Collaboration,Collaborative software,Collaborative work,Computer science,Laboratories,Physics,Programming profession,Software engineering,collaborative lab settings,computer science education,computer science educators,mypubs,natural science educators,natural sciences computing,software engineering courses},
mendeley-tags = {mypubs},
month = {jul},
pages = {72--82},
publisher = {IEEE},
shorttitle = {Software Engineering Education {\&} Training, 2007. C},
title = {{Lab Partners: If They're Good Enough for the Sciences, Why Aren't They Good Enough for Us?}},
year = {2007}
}
@inproceedings{Layman2008f,
address = {Kaiserslautern, Germany},
author = {Layman, Lucas and Kudrjavets, Gunnar and Nagappan, Nachiappan},
booktitle = {Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement - ESEM '08},
doi = {10.1145/1414004.1414038},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Layman, Kudrjavets, Nagappan - 2008 - Iterative identification of fault-prone binaries using in-process metrics.pdf:pdf},
isbn = {9781595939715},
keywords = {churn,code churn,fault prediction,mypubs,regression,statistical models},
mendeley-tags = {churn,mypubs},
month = {oct},
pages = {206--212},
publisher = {ACM Press},
title = {{Iterative identification of fault-prone binaries using in-process metrics}},
url = {http://portal.acm.org/citation.cfm?doid=1414004.1414038},
year = {2008}
}
@inproceedings{Williams2007g,
abstract = {Millennial students (those born after 1982), particularly African Americans and women, have demonstrated a propensity toward collaborative activities. We conducted a collective case study at North Carolina State University and North Carolina A{\&}T to ascertain the role of collaboration and social interaction in attracting and retaining students in information technology. Responses from semi-structured interviews with 11 representative African American students in these classes were coded and analyzed. The responses from these minority students were used to evolve a social interaction model. The conjectures generated from the model suggest that pair programming and agile software methodologies effectively create a collaborative environment that is desirable to Millennial students, male and female, and, with the new evidence, minority and majority. Additionally, the African American Millennial students enjoy learning from their peers and believe that a collaborative environment better prepares them for the "real world".},
author = {Williams, Laurie and Layman, Lucas and Slaten, Kelli M. and Berenson, Sarah B. and Seaman, Carolyn},
booktitle = {29th International Conference on Software Engineering (ICSE'07)},
doi = {10.1109/ICSE.2007.58},
isbn = {0-7695-2828-7},
issn = {0270-5257},
keywords = {African American millennial students,Collaboration,Collaborative software,Collaborative work,Computer science,Educational institutions,Engineering profession,Information technology,North Carolina State University,Programming profession,Software engineering,Switches,agile software methodologies,collaborative environment,collaborative pedagogy,computer aided instruction,computer science education,groupware,mypubs,social interaction model},
mendeley-tags = {mypubs},
month = {may},
pages = {677--687},
publisher = {IEEE},
shorttitle = {Software Engineering, 2007. ICSE 2007. 29th Intern},
title = {{On the Impact of a Collaborative Pedagogy on African American Millennial Students in Software Engineering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4222629},
year = {2007}
}
@article{Menzies2016,
abstract = {{\textcopyright} 2016, Springer Science+Business Media New York. Many practitioners and academics believe in a delayed issue effect (DIE); i.e. the longer an issue lingers in the system, the more effort it requires to resolve. This belief is often used to justify major investments in new development processes that promise to retire more issues sooner. This paper tests for the delayed issue effect in 171 software projects conducted around the world in the period from 2006–2014. To the best of our knowledge, this is the largest study yet published on this effect. We found no evidence for the delayed issue effect; i.e. the effort to resolve issues in a later phase was not consistently or substantially greater than when issues were resolved soon after their introduction. This paper documents the above study and explores reasons for this mismatch between this common rule of thumb and empirical data. In summary, DIE is not some constant across all projects. Rather, DIE might be an historical relic that occurs intermittently only in certain kinds of projects. This is a significant result since it predicts that new development processes that promise to faster retire more issues will not have a guaranteed return on investment (depending on the context where applied), and that a long-held truth in software engineering should not be considered a global truism.},
author = {Menzies, Tim and Nichols, William and Shull, Forrest and Layman, Lucas},
doi = {10.1007/s10664-016-9469-x},
file = {:C$\backslash$:/Users/laymanl/Desktop/layman pubs/Menzies2016.pdf:pdf},
issn = {15737616},
journal = {Empirical Software Engineering: An International Journal},
keywords = {Cost to fix,Phase delay,Software economics},
number = {4},
pages = {1903--1935},
title = {{Are delayed issues harder to resolve? Revisiting cost-to-fix of defects throughout the lifecycle}},
url = {http://dx.doi.org/10.1007/s10664-016-9469-x},
volume = {22},
year = {2016}
}
@inproceedings{Layman2011a,
abstract = {In this case study, we examine software safety risk in three flight hardware systems in NASA's Constellation spaceflight program. We applied our Technical and Process Risk Measurement (TPRM) methodology to the Constellation hazard analysis process to quantify the technical and process risks involving software safety in the early design phase of these projects. We analyzed 154 hazard reports and collected metrics to measure the prevalence of software in hazards and the specificity of descriptions of software causes of hazardous conditions. We found that 49-70{\%} of 154 hazardous conditions could be caused by software or software was involved in the prevention of the hazardous condition. We also found that 12-17{\%} of the 2013 hazard causes involved software, and that 23-29{\%} of all causes had a software control. The application of the TRPM methodology identified process risks in the application of the hazard analysis process itself that may lead to software safety risk. {\textcopyright} 2011 ACM.},
address = {Honolulu, HI},
author = {Layman, Lucas and Basili, Victor R and Zelkowitz, Marvin V and Fisher, Karen L},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Software Engineering (ICSE '11)},
doi = {10.1145/1985793.1985881},
isbn = {9781450304450},
issn = {02705257},
keywords = {constellation program,empirical software engineering,hazard reports,measurement,mypubs,safety},
mendeley-tags = {mypubs},
pages = {623--632},
title = {{A Case Study of Measuring Process Risk for Early Insights into Software Safety}},
year = {2011}
}
@inproceedings{Layman2015,
abstract = {{\textcopyright} 2015 IEEE. Maturity in software projects is often equated with data-driven predictability. However, data collection is expensive and measuring all variables that may correlate with project outcome is neither practical nor feasible. In contrast, a project engineer can identify a handful of factors that he or she believes influence the success of a project. The challenge is to quantify engineers' insights in a way that is useful for data analysis. In this exploratory study, we investigate the repertory grid technique for this purpose. The repertory grid technique is an interview-based procedure for eliciting 'constructs' (e.g., Adhering to coding standards) that individuals believe influence a worldly phenomenon (e.g., What makes a high-quality software project) by comparing example elements from their past (e.g., Projects they have worked on). We investigate the relationship between objective metrics of project performance and repertory grid constructs elicited from eight software engineers. Our results show correlations between the engineers' subjective constructs and the objective project outcome measures. This suggests that repertory grids may be of benefit in developing models of project outcomes, particularly when project data is limited.},
address = {Florence, Italy},
author = {Layman, Lucas and Seaman, Carolyn and Falessi, Davide and Diep, Madeline},
booktitle = {8th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE 2015)},
doi = {10.1109/CHASE.2015.25},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Layman et al. - 2015 - Ask the Engineers Exploring Repertory Grids and Personal Constructs for Software Data Analysis.pdf:pdf},
isbn = {9781479919345},
keywords = {agile,mypubs,nsf,practitioners,repertory grids,software data analytics},
mendeley-tags = {agile,mypubs,nsf},
pages = {81--84},
title = {{Ask the Engineers: Exploring Repertory Grids and Personal Constructs for Software Data Analysis}},
year = {2015}
}
@inproceedings{Peters2015,
abstract = {{\textcopyright} 2015 IEEE. Before a community can learn general principles, it must share individual experiences. Data sharing is the fundamental step of cross project defect prediction, i.e. the process of using data from one project to predict for defects in another. Prior work on secure data sharing allowed data owners to share their data on a single-party basis for defect prediction via data minimization and obfuscation. However the studied method did not consider that bigger data required the data owner to share more of their data. In this paper, we extend previous work with LACE2 which reduces the amount of data shared by using multi-party data sharing. Here data owners incrementally add data to a cache passed among them and contribute "interesting" data that are not similar to the current content of the cache. Also, before data owner i passes the cache to data owner j, privacy is preserved by applying obfuscation algorithms to hide project details. The experiments of this paper show that (a) LACE2 is comparatively less expensive than the single-party approach and (b) the multiparty approach of LACE2 yields higher privacy than the prior approach without damaging predictive efficacy (indeed, in some cases, LACE2 leads to better defect predictors).},
address = {Florence, Italy},
author = {Peters, Fayola and Menzies, Tim and Layman, Lucas},
booktitle = {37th International Conference on Software Engineering (ICSE '15)},
doi = {10.1109/ICSE.2015.92},
file = {:C$\backslash$:/Users/laymanl/Desktop/layman pubs/Peters2015.pdf:pdf},
isbn = {9781479919345},
issn = {02705257},
keywords = {agile,mypubs,nsf},
mendeley-tags = {agile,mypubs,nsf},
pages = {801--811},
title = {{LACE2: Better Privacy-Preserving Data Sharing for Cross Project Defect Prediction}},
volume = {1},
year = {2015}
}
@article{Layman2013b,
abstract = {Determining whether systems achieve desired emergent properties, such as safety or reliability, requires an analysis of the system as a whole, often in later development stages when changes are difficult and costly to implement. In this article we propose the Process Risk Indicator (PRI) methodology for analyzing and evaluating emergent properties early in the development cycle. A fundamental assumption of system engineering is that risk mitigation processes reduce system risks, yet these processes may also be a source of risk: (1) processes may not be appropriate for achieving the desired emergent property; or (2) processes may not be followed appropriately. PRI analyzes development process artifacts (e.g., designs pertaining to reliability or safety analysis reports) to quantify process risks that may lead to higher system risk.We applied PRI to the hazard analysis processes of a network-centric, Department of Defense system-of-systems and two NASA spaceflight projects to assess the risk of not achieving one such emergent property, software safety, during the early stages of the development lifecycle. The PRI methodology was used to create measurement baselines for process indicators of software safety risk, to identify risks in the hazard analysis process, and to provide feedback to projects for reducing these risks. {\textcopyright} 2014 ACM.},
author = {Layman, Lucas and Basili, Victor R and Zelkowitz, Marvin V},
doi = {10.1145/2560048},
file = {:C$\backslash$:/Users/laymanl/Desktop/layman pubs/Layman2013b.pdf:pdf},
issn = {15577392},
journal = {Transactions on Software Engineering Methodology},
keywords = {Process risk,Risk measurement,Software safety,mypubs},
mendeley-tags = {mypubs},
number = {3},
pages = {Article 22},
title = {{A Methodology for Exposing Risk in Achieving Emergent System Properties}},
volume = {22},
year = {2014}
}
@inproceedings{Basili2010c,
abstract = {We report on a preliminary case study to examine software safety risk in the early design phase of the NASA Constellation spaceflight program. Our goal is to provide NASA quality assurance managers with information regarding the ongoing state of software safety across the program. We examined 154 hazard reports created during the preliminary design phase of three major flight hardware systems within the Constellation program. Our purpose was two-fold: 1) to quantify the relative importance of software with respect to system safety; and 2) to identify potential risks due to incorrect application of the safety process, deficiencies in the safety process, or the lack of a defined process. One early outcome of this work was to show that there are structural deficiencies in collecting valid safety data that make software safety different from hardware safety. In our conclusions we present some of these deficiencies. {\textcopyright} 2010 ACM.},
address = {Bolzano, Italy},
author = {Basili, Victor R and Zelkowitz, Marvin V and Layman, Lucas and Dangle, Kathleen and Diep, Madeline},
booktitle = {Proceedings of the 4th ACM/IEEE International Symposium on Empirical Soiftware Engineering and Measurement (ESEM '10)},
doi = {10.1145/1852786.1852846},
isbn = {9781450300391},
keywords = {NASA,case study,mypubs,nasa,risk analysis,safety metrics},
mendeley-tags = {mypubs},
pages = {Article No. 46},
title = {{Obtaining Valid Safety Data for Software Safety Measurement and Process Improvement}},
year = {2010}
}
@inproceedings{Slaten2005,
abstract = {One of the reasons that undergraduate students, particularly women and minorities, can become disenchanted with computer science education is because software development is wrongly characterized as a solitary activity. We conducted a collective case study in a software engineering course at North Carolina State University to ascertain the effects of a collaborative pedagogy intervention on student perceptions. The pedagogy intervention was based upon the practices of agile software development with a focus on pair programming. Six representative students in the course participated in the study. Their perspectives helped validate a social interaction model of student views. The findings suggest that pair programming and agile software methodologies contribute to more effective learning opportunities for computer science students and that students understand and appreciate these benefits.},
address = {Denver, CO},
author = {Slaten, Kelli M and Droujkova, Maria and Berenson, Sarah B and Williams, Laurie and Layman, Lucas},
booktitle = {Agile Development Conference (ADC'05)},
doi = {10.1109/ADC.2005.48},
isbn = {0-7695-2487-7},
keywords = {Collaborative software,Collaborative work,Computer science,Computer science education,Educational programs,Iterative methods,Mathematical model,Mathematics,North Carolina State University,Programming profession,Software engineering,agile software development,collaborative pedagogy intervention,computer science students,educational courses,mypubs,pair programming,qualitative,simpp,social interaction model,software engineering course,undergraduate student perception},
mendeley-tags = {mypubs},
pages = {323--330},
publisher = {IEEE Comput. Soc},
shorttitle = {Agile Conference, 2005. Proceedings},
title = {{Undergraduate Student Perceptions of Pair Programming and Agile Software Methodologies: Verifying a Model of Social Interaction}},
year = {2005}
}
@inproceedings{Layman2010,
abstract = {Our current research is focused on identifying system engineering approaches that address four key development challenges in a tightly constrained, rapid reaction environment: 1) changing and emerging requirements; 2) conflicting stakeholder priorities; 3) concurrent sustainment and development activities; and 4) integration of independently evolving components. We are building a concept map of the key elements that form a strategic bridge between development challenges and the specific methods, processes, and tools that successfully address those challenges. In this paper, we present our methodology for constructing a robust mapping that incorporates interviews, surveys, and rigorous analysis methods. We summarize the results from interviews with sponsor personnel, the results of a best practices survey of 116 professionals, and qualitative analysis of the survey responses. {\textcopyright}2010 IEEE.},
address = {San Diego, CA},
author = {Layman, Lucas and Shull, Forrest and Componation, Paul and O'Brien, S. and Sabados, D. and Carrigy, Anne and Turner, Richard and Brien, Sue O and Carrigy, Anne and Turner, Richard},
booktitle = {Proceedings of the 4th Annual IEEE International Systems Conference},
doi = {http://dx.doi.org/10.1109/SYSTEMS.2010.5482336},
isbn = {9781424458837},
keywords = {Methodology,Qualitative analysis,Software engineering,Survey,Systems engineering,modeling,mypubs,systems engineering},
mendeley-tags = {mypubs},
pages = {294--299},
title = {{A Methodology for Mapping System Engineering Challenges to Recommended Approaches}},
year = {2010}
}

@book{Diep2015,
abstract = {{\textcopyright} 2015 Elsevier Inc. All rights reserved. Software data analytics is key for helping stakeholders make decisions, and thus establishing a measurement and data analysis program is a recognized best practice within the software industry. However, practical implementation of measurement programs and analytics in industry is challenging. In this chapter, we discuss real-world challenges that arise during the implementation of a software measurement and analytics program. We also report lessons learned for overcoming these challenges and best practices for practical, effective data analysis in industry. The lessons learned provide guidance for researchers who wish to collaborate with industry partners in data analytics, as well as for industry practitioners interested in setting up and realizing the benefits of an effective measurement program.},
author = {Diep, M. and Esker, L. and Falessi, D. and Layman, L. and Shaw, M. and Shull, F.},
booktitle = {The Art and Science of Analyzing Software Data},
doi = {10.1016/B978-0-12-411519-4.00012-4},
isbn = {9780124115439},
keywords = {Data Analysis,Practical Software Measurement,Software Best Practices,Software Industry Challenges},
title = {{Applying Software Data Analysis in Industry Contexts: When Research Meets Reality}},
year = {2015}
}
@inproceedings{Layman2016a,
abstract = {{\textcopyright} 2016 ACM. Problem reports at NASA are similar to bug reports: they capture defects found during test, post-launch operational anomalies, and document the investigation and corrective action of the issue. These artifacts are a rich source of lessons learned for NASA, but are expensive to analyze since problem reports are comprised primarily of natural language text. We apply topic modeling to a corpus of NASA problem reports to extract trends in testing and operational failures. We collected 16,669 problem reports from six NASA space flight missions and applied Latent Dirichlet Allocation topic modeling to the document corpus. We analyze the most popular topics within and across missions, and how popular topics changed over the lifetime of a mission. We find that hardware material and flight software issues are common during the integration and testing phase, while ground station software and equipment issues are more common during the operations phase. We identify a number of challenges in topic modeling for trend analysis: 1) that the process of sele cting the topic modeling parameters lacks definitive guidance, 2) defining semantically-meaningful topic labels requires nontrivial effort and domain expertise, 3) topic models derived from the combined corpus of the six missions were biased toward the larger missions, and 4) topics must be semantically distinct as well as cohesive to be useful. Nonetheless, topic modeling can identify problem themes within missions and across mission lifetimes, providing useful feedback to engineers and project managers.},
author = {Layman, L. and Nikora, A.P. and Meek, J. and Menzies, T.},
booktitle = {Proceedings - 13th Working Conference on Mining Software Repositories, MSR 2016},
doi = {10.1145/2901739.2901760},
isbn = {9781450341868},
keywords = {Data mining,Defects,LDA,Natural language processing,Topic modeling},
title = {{Topic modeling of NASA space system problem reports research in practice}},
year = {2016}
}
@inproceedings{Layman2007,
abstract = {This paper describes an initiative at North Carolina State University in which the undergraduate software engineering class was restructured in layout and in presentation. The change was made from a lecture-based coursed that followed the waterfall method to a lab-oriented course emphasizing practical tools and agile processes. We examine the new course layout from the perspective of Myers-Briggs personality types and Felder-Silverman learning styles to discuss how the new software engineering class format appeals to a wide variety of students. The new course format resulted in some of the highest student evaluations in recent course history. It is now the standard for the undergraduate software engineering course at the university and has since been used in other North Carolina institutions. Copyright 2006 ACM.},
author = {Layman, L. and Cornwell, T. and Williams, L.},
booktitle = {Proceedings of the Thirty-Seventh SIGCSE Technical Symposium on Computer Science Education},
doi = {10.1145/1121341.1121474},
isbn = {9781595932594},
keywords = {Agile methods,Learning styles,Personality types,Software engineering education},
title = {{Personality types, learning styles, and an agile approach to software engineering education}},
year = {2007}
}
@inproceedings{Layman2014,
abstract = {The InViz tool is a functional prototype that provides graphical visualizations of log file events to support real-time attack investigation. Through visualization, both experts and novices in cybersecurity can analyze patterns of application behavior and investigate potential cybersecurity attacks. The goal of this research is to identify and evaluate the cybersecurity information to visualize that reduces the amount of time required to perform cyber forensics.},
author = {Layman, L. and Zazworka, N.},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2600176.2600191},
isbn = {9781450329071},
keywords = {Cybersecurity,Log file,Real-time analysis,Visualization},
title = {{InViz: Instant visualization of security attacks}},
year = {2014}
}
@inproceedings{Williams2004,
abstract = {Software organizations are progressively adopting the development practices associated with the extreme programming (XP) methodology. Most reports on the efficacy of these practices are anecdotal. This paper provides a benchmark measurement framework for researchers and practitioners to express concretely the XP practices the organization has selected to adopt and/or modify, and the outcome thereof. The framework enables the necessary meta-analysis for combining families of case studies. The results of running framework-based case studies in various contexts will eventually constitute a body of knowledge of systematic, empirical evaluations of XP and its practices. Additionally, this benchmark provides a baseline framework that can be adapted for industrial case studies of other technologies and processes. To provide a foundation on the use of the framework, we present the initial validation of our XP evaluation framework based upon a year-long study of an IBM team that adopted a subset of XP practices.},
address = {Edinburgh, Scotland},
annote = {From Duplicate 1 (Toward a Framework for Evaluating Extreme Programming - Williams, Laurie; Krebs, William; Layman, Lucas; Anton, Annie I; Abrahamsson, Pekka)

rejected icse paper},
author = {Williams, Laurie and Krebs, William and Layman, Lucas and Anton, Annie I and Abrahamsson, Pekka},
booktitle = {Proceedings of the 8th International Conference on Evaluation and Assessment in Software Engineering (EASE '04)},
keywords = {mypubs},
mendeley-tags = {mypubs},
pages = {11--20},
publisher = {IET Digital Library},
title = {{Toward a Framework for Evaluating Extreme Programming}},
url = {https://www.researchgate.net/profile/Annie-Anton/publication/228455028_Toward_a_framework_for_evaluating_extreme_programming/links/545f8e240cf27487b450a7a2/Toward-a-framework-for-evaluating-extreme-programming.pdf},
year = {2004}
}
@inproceedings{Falessi2013d,
abstract = {NASA anomaly databases are rich resources of software failure data in the field. These data are often captured in natural language that is not appropriate for trending or statistical analyses. This fast abstract describes a feasibility study of applying 60 natural language processing techniques for automatically classifying anomaly data to enable trend analyses.},
address = {Pasadena, CA},
author = {Falessi, Davide and Layman, Lucas},
booktitle = {2013 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)},
doi = {10.1109/ISSREW.2013.6688849},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Falessi, Layman - 2013 - Automated classification of NASA anomalies using natural language processing techniques.pdf:pdf},
isbn = {978-1-4799-2552-0},
keywords = {NLP,mypubs,natural language processing,software failure},
mendeley-tags = {mypubs},
month = {nov},
pages = {5--6},
publisher = {IEEE},
shorttitle = {Software Reliability Engineering Workshops (ISSREW},
title = {{Automated classification of NASA anomalies using natural language processing techniques}},
year = {2013}
}
@inproceedings{Layman2016,
address = {Austin, TX},
author = {Layman, Lucas and Nikora, Allen P. and Meek, Joshua and Menzies, Tim},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories (MSR '16)},
file = {:C$\backslash$:/Users/laymanl/Desktop/layman pubs/Layman2016.pdf:pdf},
pages = {303--314},
title = {{Topic Modeling of NASA Space System Problem Reports}},
year = {2016}
}
@phdthesis{Layman2008e,
author = {Layman, Lucas},
keywords = {mypubs},
mendeley-tags = {mypubs},
school = {North Carolina State University},
title = {{Information Needs of Developers for Program Comprehension during Software Maintenance Tasks}},
type = {Ph.D. Dissertation},
url = {http://repository.lib.ncsu.edu/ir/bitstream/1840.16/3703/1/etd.pdf},
year = {2008}
}
@misc{Williams2003c,
address = {North Carolina State University, Department of Computer Science TR-2003-18},
author = {Williams, Laurie and Krebs, William and Layman, Lucas and Anton, Annie I.},
keywords = {mypubs},
mendeley-tags = {mypubs},
title = {{Toward an XP Evaluation Framework}},
year = {2003}
}
@misc{Krebs2005,
address = {North Carolina State University, Department of Computer Science TR-2005-46 (http://goo.gl/PqS8WZ)},
author = {Krebs, Williams and Ho, Chih-Wei and Williams, Laurie and Layman, Lucas},
keywords = {mypubs},
mendeley-tags = {mypubs},
title = {{Rational Unified Process Evaluation Framework Version 1.0}},
year = {2005}
}
@misc{Layman2005c,
address = {North Carolina State University, Department of Computer Science TR-2005-40 (http://goo.gl/3izvne)},
author = {Layman, Lucas and Cornwell, Travis and Williams, Laurie and Osborne, Jason},
keywords = {mypubs},
mendeley-tags = {mypubs},
title = {{Personality Profiles and Learning Styles of Advanced Undergraduate Computer Science Students}},
year = {2005}
}
@misc{Layman2010a,
address = {NASA Technical Report 20100031198},
author = {Layman, Lucas and Basili, Victor R. and Zelkowitz, Marvin V.},
keywords = {mypubs},
mendeley-tags = {mypubs},
publisher = {NASA},
title = {{The Role and Quality of Software Safety in the NASA Constellation Program}},
year = {2010}
}
@misc{Basili2011,
address = {Fraunhofer Center for Experimental Software Engineering TR 11-101 (http://goo.gl/fEKc2)},
author = {Basili, Victor R. and Layman, Lucas and Zelkowitz, Marvin V.},
keywords = {mypubs},
mendeley-tags = {mypubs},
publisher = {Fraunhofer Center for Experimental Software Engineering},
title = {{A Methodology for Exposing Software Development Risk in Emergent System Properties}},
year = {2011}
}
@inproceedings{Gallagher2003,
abstract = {When computing program slices on all variables in a system, we observed that many of these slices are the same. This leads to the question: Are we looking at software clones? We discuss the genesis of this phenomena and present some of the data observations that led to the question. The answer to our query is not immediately clear. We end by presenting arguments both pro and con. Supporting the affirmative, we observed that some slice-clones are evidently the result of the usual genesis of software clones: failure to note appropriate abstractions. Also, slice-clones assist in program comprehension by coalescing into one program fragment the computations on many different variables. Opposing the proposition, we note that slice-clones do not arise due to programmer intent or the copying of existing idioms.},
author = {Gallagher, K. and Layman, L.},
booktitle = {Proceedings of the 11th International Workshop on Program Comprehension (IWPC '03)},
doi = {10.1109/WPC.2003.1199209},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gallagher, Layman - 2003 - Are decomposition slices clones.pdf:pdf},
isbn = {0-7695-1883-4},
issn = {1092-8138},
keywords = {Accidents,Automatic control,Cloning,Computer science,Data analysis,Displays,Educational institutions,Programming profession,Reverse engineering,Software maintenance,mypubs,program comprehension,program fragment,program slices,program slicing,software clones},
mendeley-tags = {mypubs},
pages = {251--256},
publisher = {IEEE Comput. Soc},
shorttitle = {Program Comprehension, 2003. 11th IEEE Internation},
title = {{Are decomposition slices clones?}},
year = {2003}
}
@inproceedings{Layman2004c,
address = {New York, New York, USA},
author = {Layman, Lucas},
booktitle = {Companion to the 19th annual ACM SIGPLAN conference on Object-oriented programming systems, languages, and applications - OOPSLA '04},
doi = {10.1145/1028664.1028787},
isbn = {1581138334},
keywords = {agile software development,case studies,extreme programming,mypubs},
mendeley-tags = {mypubs},
month = {oct},
pages = {328},
publisher = {ACM Press},
title = {{Empirical investigation of the impact of extreme programming practices on software projects}},
year = {2004}
}
@article{Williams2005,
author = {Williams, Laurie and Layman, Lucas and Abrahamsson, Pekka},
doi = {10.1145/1082983.1083179},
isbn = {1-59593-121-X},
issn = {01635948},
journal = {ACM SIGSOFT Software Engineering Notes},
keywords = {mypubs},
mendeley-tags = {mypubs},
month = {jul},
number = {4},
pages = {1},
publisher = {ACM},
title = {{On establishing the essential components of a technology-dependent framework}},
volume = {30},
year = {2005}
}
@inproceedings{Layman2006d,
author = {Layman, Lucas},
booktitle = {International Doctoral Symposium on Empirical Software Engineering (IDoESE '06)},
keywords = {mypubs},
mendeley-tags = {mypubs},
title = {{Intelligent User Notifaction to Expedite Awareness of Fault Code}},
year = {2006}
}
@inproceedings{Layman2008d,
address = {New York, New York, USA},
author = {Layman, Lucas and Nagappan, Nachiappan and Guckenheimer, Sam and Beehler, Jeff and Begel, Andrew},
booktitle = {Proceedings of the 2008 International Working Conference on Mining software repositories - MSR '08},
doi = {10.1145/1370750.1370762},
isbn = {9781605580241},
keywords = {effort estimation,mypubs,prediction},
mendeley-tags = {mypubs},
month = {may},
pages = {43--46},
publisher = {ACM Press},
title = {{Mining software effort data: A preliminary analysis of Visual Studio Team System Data}},
year = {2008}
}
@inproceedings{Layman2006c,
abstract = {Collaborative work has been in use as an instructional tool to increase student understanding through collaborative learning and to improve student performance in computer science courses. However, little work has been done to understand how the act of collaboration, through pair programming or group work, impacts a student's knowledge of the benefits and difficulties of collaborative work experience in collaborative work is essential preparation for professional software development. A study was conducted at North Carolina State University to assess changes in advanced undergraduate students' perceptions of pair programming and collaboration. Student personality types, learning styles, and other characteristics were gathered during two semesters of an undergraduate software engineering course. The study found that, after experiencing pair programming, most students indicated a stronger preference to work with another student, believed that pairing made them more organized, and believed that pairing saved time on homework assignments. Students who disliked their collaborative experiences were predominantly reflective learners, introverts, and strong coders. Those students also cited that a non-participatory partner and difficulties scheduling meeting times outside of the classroom were primary reasons for disliking pair programming. Personality type and learning style had little effect on the changes in perceptions of collaboration},
author = {Layman, L.},
booktitle = {19th Conference on Software Engineering Education and Training (CSEET'06)},
doi = {10.1109/CSEET.2006.10},
isbn = {0-7695-2557-1},
issn = {1093-0175},
keywords = {Collaboration,Collaborative software,Collaborative work,Computer science,Educational programs,Engineering management,North Carolina State University,Processor scheduling,Programming profession,Software engineering,Teamwork,advanced undergraduate students,collaborative learning,collaborative software development,collaborative work experience,computer science courses,computer science education,continuing education,educational courses,group work,homework assignments,mypubs,pair programming,professional software development,student learning styles,student perceptions,student personality types,student understanding,teaching},
mendeley-tags = {mypubs},
pages = {159--166},
publisher = {IEEE},
shorttitle = {Software Engineering Education and Training, 2006.},
title = {{Changing Students' Perceptions: An Analysis of the Supplementary Benefits of Collaborative Software Development}},
year = {2006}
}
@inproceedings{Layman2007c,
address = {Covington, KY},
author = {Layman, Lucas and Williams, Laurie and Slaten, Kelli},
booktitle = {Proceedings of the 28th SIGCSE Technical Symposium on Computer Science Education},
doi = {10.1145/1227504.1227466},
isbn = {1-59593-361-1},
issn = {00978418},
keywords = {CS1,mypubs,programming assignments,software engineering education},
mendeley-tags = {mypubs},
month = {mar},
pages = {459--463},
publisher = {ACM},
title = {{Note to self: Make Assignments Meaningful}},
year = {2007}
}
@inproceedings{Williams2008a,
abstract = {Utilizing pair programming in the classroom requires specific classroom management techniques. We have created nine guidelines for successfully implementing pair programming in the classroom. These guidelines are based on pair programming experiences spanning seven years and over one thousand students at North Carolina State University. In Fall 2007, pair programming was adopted in the undergraduate human-computer interaction (HCI) course at Virginia Tech. We present the pair programming guidelines in the context of the HCI course, discuss how the guidelines were implemented, and evaluate the general applicability and sufficiency of the guidelines. We find that eight of the nine guidelines were applicable to the Virginia Tech experience. We amended our peer evaluation guideline to account for constantly supervised pairing, as was the case at Virginia Tech. We add two guidelines stating that a pair should always be working toward a common goal and that pairs should be encouraged to find their own answers to increase their independence and self-confidence.},
author = {Williams, Laurie and McCrickard, D. Scott and Layman, Lucas and Hussein, Khaled},
booktitle = {Agile 2008 Conference},
doi = {10.1109/Agile.2008.12},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Williams et al. - 2008 - Eleven Guidelines for Implementing Pair Programming in the Classroom.pdf:pdf},
isbn = {978-0-7695-3321-6},
keywords = {Computer science,Conference management,Costs,Guidelines,Human computer interaction,Laboratories,Programming profession,Software engineering,classroom management techniques,collaboration,education,educational computing,mypubs,pair programming,supervised pairing,undergraduate human-computer interaction course},
mendeley-tags = {mypubs},
pages = {445--452},
publisher = {IEEE},
shorttitle = {Agile, 2008. AGILE '08. Conference},
title = {{Eleven Guidelines for Implementing Pair Programming in the Classroom}},
year = {2008}
}
@inproceedings{Layman2013a,
abstract = {Amazon's Mechanical Turk is a crowdsourcing technology that enables requesters to create tasks to be completed by human agents in exchange for compensation. Researchers in computer science have successfully used this service to quickly reach large numbers of subjects for a relatively low cost. However, the Mechanical Turk's model and policies introduce several experimental limitations and threats that must be controlled. In this short paper, we describe limitations imposed using Amazon's Mechanical Turk during an experiment on cyber-attack investigation techniques. While the experiment was successful, we were forced to change our experimental design and had to recover from some costly mistakes. The goal of this short paper is to identify these limitations and pitfalls and provide eight considerations for experimental design so that other researchers can maximize the benefits of using the Mechanical Turk as a research platform.},
address = {Baltimore, Maryland, USA},
author = {Layman, Lucas and Sigurdsson, Gunnar},
booktitle = {Proceedings of the 7th International Symposium on Empirical Software Engineering and Measurement (ESEM 2013)},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Layman, Sigurdsson - 2013 - Using Amazon's Mechanical Turk for User Studies Eight Things You Need to Know.pdf:pdf},
keywords = {amazon,experimentation,mechanical turk,mypubs,study design,user studies},
mendeley-tags = {amazon,experimentation,mechanical turk,mypubs,study design,user studies},
pages = {275--278},
title = {{Using Amazon's Mechanical Turk for User Studies: Eight Things You Need to Know}},
year = {2013}
}
@incollection{Turhan2010,
address = {Cambridge, MA},
author = {Turhan, Burak and Layman, Lucas and Diep, Madeline and Erdogmus, Hakan and Shull, Forrest},
booktitle = {Making Software: What Really Works, and Why We Believe It},
editor = {Oram, Andy and Wilson, Greg},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Turhan et al. - 2010 - How Effective is Test Driven Development.pdf:pdf},
keywords = {mypubs},
mendeley-tags = {mypubs},
pages = {207--219},
publisher = {O'Reilly},
title = {{How Effective is Test Driven Development?}},
year = {2010}
}
@inproceedings{Layman2012,
abstract = {In this fast abstract, we provide preliminary findings from an analysis of 14,500 spacecraft anomalies from unmanned NASA missions. We provide some baselines for the distributions of software vs. non-software anomalies in spaceflight systems, the risk ratings of software anomalies, and the corrective actions associated with software anomalies.},
address = {Dallas, Texas, USA},
author = {Layman, Lucas and Zelkowitz, Marvin and Basili, Victor and Nikora, Allen P},
booktitle = {2012 IEEE 23rd International Symposium on Software Reliability Engineering Workshops},
doi = {10.1109/ISSREW.2012.49},
isbn = {978-1-4673-5048-8},
keywords = {anomalies,baseline,metrics,mypubs,nasa},
mendeley-tags = {mypubs},
month = {nov},
pages = {13--14},
publisher = {IEEE},
title = {{Toward Baselining Software Anomalies in NASA Missions}},
year = {2012}
}
@article{Shull2010a,
abstract = {What if someone argued that one of your basic conceptions about how to develop software was misguided? What would it take to change your mind? That's essentially the dilemma faced by advocates of test-driven development (TDD). The TDD paradigm argues that the basic cycle of developing code and then testing it to make sure it does what it's supposed to do-something drilled into most of us from the time we began learning software development- isn't the most effective approach. TDD replaces the traditional "code then test" cycle. First, you develop test cases for a small increment of functionality; then you write code that makes those tests run correctly. After each increment, you refactor the code to maintain code quality.},
author = {Shull, Forrest and Melnik, Grigori and Turhan, Burak and Layman, Lucas and Diep, Madeline and Erdogmus, Hakan},
doi = {http://dx.doi.org/10.1109/MS.2010.152},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shull et al. - 2010 - What Do We Know about Test-Driven Development.pdf:pdf},
journal = {IEEE Software},
keywords = {mypubs},
mendeley-tags = {mypubs},
number = {6},
pages = {16--19},
title = {{What Do We Know about Test-Driven Development}},
volume = {27},
year = {2010}
}
@techreport{Turner2009,
abstract = {Final Technical Report},
author = {Turner, R. and Shull, F. and Boehm, B. and Carrigy, A. and Clarke, L. and Componation, P. and Dagli, C. and Lane, J. and Layman, L. and Miller, A. and O'Brien, S. and Osterweil, L. and Sabados, D. and Wise, S.},
institution = {Systems Engineering Research Center SERC-2009-TR004},
keywords = {mypubs},
mendeley-tags = {mypubs},
title = {{Evaluation of Systems Engineering Methods, Processes and Tools on Department of Defense and Intelligence Community Programs}},
year = {2009}
}
@inproceedings{Begel2009,
address = {Vancouver, BC},
author = {Begel, Andrew and Nagappan, Nachiappan and Poile, Christopher and Layman, Lucas},
booktitle = {2009 ICSE Workshop on Cooperative and Human Aspects on Software Engineering},
doi = {10.1109/CHASE.2009.5071401},
isbn = {978-1-4244-3712-2},
keywords = {mypubs},
mendeley-tags = {mypubs},
month = {may},
pages = {1--7},
publisher = {IEEE},
title = {{Coordination in large-scale software teams}},
year = {2009}
}
@inproceedings{Layman2008a,
address = {Leipzig, Germany},
author = {Layman, Lucas M and Williams, Laurie A and {St. Amant}, Robert},
booktitle = {1st Workshop on Cooperative and Human Aspects of Software Engineering (CHASE '08)},
keywords = {mypubs},
mendeley-tags = {mypubs},
pages = {73--76},
title = {{MimEc: Intelligent User Notification of Faults in the Eclipse IDE}},
year = {2008}
}
@inproceedings{Layman2004,
address = {Salt Lake City, UT},
author = {Layman, L and Williams, L and Cunningham, L},
booktitle = {Agile Development Conference 2004 (ADC'04)},
keywords = {mypubs},
mendeley-tags = {mypubs},
pages = {32--41},
title = {{Exploring Extreme Programming in Context: An Industrial Case Study}},
year = {2004}
}
@misc{Layman2004a,
address = {Raleigh, NC},
author = {Layman, L},
keywords = {mypubs},
mendeley-tags = {mypubs},
publisher = {North Carolina State University},
title = {{Identifying Potential Deficiencies in Agile Requirements Engineering Practices}},
year = {2004}
}
@article{Layman2006g,
author = {Layman, Lucas and Williams, Laurie and Damian, Daniela and Bures, Hynek},
journal = {Information and Software Technology},
keywords = {mypubs},
mendeley-tags = {mypubs},
number = {9},
pages = {781--794},
title = {{Essential Communication Practices for Extreme Programming in a Global Software Development Team}},
volume = {48},
year = {2006}
}
@inproceedings{Layman2004b,
address = {Newport Beach, CA},
author = {Layman, L and Williams, L and Cunningham, L},
keywords = {mypubs},
mendeley-tags = {mypubs},
pages = {to appear},
title = {{Motivations and Measurements in an Agile Case Study}},
year = {2004}
}
@inproceedings{Williams2007c,
address = {Minneapolis, MN},
author = {Williams, Laurie and Layman, Lucas and Slaten, Kelli M and Seaman, Carolyn and Berenson, Sarah B},
pages = {677--687},
title = {{On the Impact of a Collaborative Pedagogy on African-American Millennial Students in Software Engineering}},
year = {2007}
}
@inproceedings{Layman2006a,
address = {Houston, TX},
author = {Layman, Lucas and Cornwell, Travis and Williams, Laurie},
booktitle = {Proceedings of the 37th SIGCSE Technical Symposium on Computer Science Education},
keywords = {learning styles,mypubs,personality,personality types},
mendeley-tags = {mypubs},
pages = {428--432},
title = {{Personality Types, Learning Styles, and an Agile Approach to Software Engineering Education}},
year = {2006}
}
@misc{WilliamsL.LaymanandW.Krebs2004,
address = {North Carolina State University, Department of Computer Science TR-2004-3 (http://goo.gl/9lz5Yb)},
author = {Williams, Laurie and Layman, Lucas and Krebs, William and Anton, Annie I.},
isbn = {TR-2004-3},
keywords = {mypubs},
mendeley-tags = {mypubs},
publisher = {North Carolina State University Department of Computer Science},
title = {{Exploring the Use of a Safe Subset of Extreme Programming: An Industrial Case Study}},
year = {2004}
}
@article{Layman2006,
author = {Layman, Lucas and Williams, Laurie and Cunningham, Lynn},
journal = {Journal of Systems Architecture},
keywords = {mypubs},
mendeley-tags = {mypubs},
number = {11},
pages = {654--667},
title = {{Motivations and Measurements in an Agile Case Study}},
volume = {52},
year = {2006}
}
